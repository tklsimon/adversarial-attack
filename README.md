# README

This is a readme.  

This project is a group project for HKU STAT7008.  

The topic is Adversary Attack.

Projected Gradient Descent:

A white-box attack, the attacker has access to the model gradients, so can design specifically to fool the trained model.
It is a constrained optimisation problem: PGD attempts to find the perturbation that maximises the loss of a model on particular input while keeping the size of the perturbation smaller than a specified amount named epsilon.

![image](https://github.com/tklsimon/adversarial-attack/assets/46237598/30dfc32b-95af-400b-a6a5-97e23e0cdef4)
